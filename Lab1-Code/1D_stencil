#include <iostream>
#include<time.h> //to compute the performance time
#include<stdio.h>
 #include <algorithm> //defines a collection of functions especially designed to be used on ranges of elements.
using namespace std;
#define N 512   //total number of threads  //initially N=1024 
#define RADIUS 3  //radius of stencil // initially R=3
#define BLOCK_SIZE 8 //number of thread per block   //initially Blocksize =16
__global__ void stencil_1d(int *in, int *out) {
__shared__ int temp[BLOCK_SIZE + 2 * RADIUS];
 int gindex = threadIdx.x + blockIdx.x * blockDim.x;
 int lindex = threadIdx.x + RADIUS;
// Read input elements into shared memory 
temp[lindex] = in[gindex];
if (threadIdx.x < RADIUS) {
temp[lindex - RADIUS] = in[gindex - RADIUS];
 temp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];
}
// Synchronize (ensure all the data is available) 
__syncthreads();
// Apply the stencil 
int result = 0;
for (int offset = -RADIUS ; offset <= RADIUS ; offset++)
result += temp[lindex + offset];

// Store the result 
out[gindex] = result;
}
void fill_ints(int *x, int n)
 {
 fill_n(x, n, 1);
}

int main(void)
 {
float time;
int *in, *out;
//int i;
int size = (N + 2*RADIUS) * sizeof(int);
// host copies of a, b, c?// device copies of a, b, c 
//host code 
// Alloc space for host copies and setup values 
in = (int *)malloc(size); fill_ints(in, N + 2*RADIUS);
 out = (int *)malloc(size); fill_ints(out, N + 2*RADIUS);
int *d_in, *d_out;

// Alloc space for (GPU)device copies 
cudaMalloc((void **)&d_in, size);
 cudaMalloc((void **)&d_out, size);
// Copy to GPU (device) 
cudaMemcpy(d_in, in, size, cudaMemcpyHostToDevice);
 cudaMemcpy(d_out, out, size, cudaMemcpyHostToDevice);

//record the time before kernel launch
//float time;
cudaEvent_t start, stop;
cudaEventCreate(&start);
cudaEventCreate(&stop);
cudaEventRecord(start, 0);

// Launch stencil_1d() kernel on GPU 
stencil_1d<<<N/BLOCK_SIZE,BLOCK_SIZE>>>(d_in + RADIUS, d_out + RADIUS);

// record the time after kernel launch
cudaEventRecord(stop, 0);
cudaEventSynchronize(stop);
cudaEventElapsedTime(&time, start, stop);
 printf("GPU Time[in ms] %f \n ", time);

// Copy result back to (host)CPU 
cudaMemcpy(out, d_out, size, cudaMemcpyDeviceToHost);

// Freeing the allocated memory 
free(in);
 free(out);
cudaFree(d_in); cudaFree(d_out); return 0;
}